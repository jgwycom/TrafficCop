#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# é¢æ¿æœºï¼šTrafficCop ç®¡æ§åç«¯ï¼ˆFlask + SQLite + APSchedulerï¼‰
# åŠŸèƒ½ï¼š
# - èŠ‚ç‚¹ CRUD / é…ç½®ä¸‹å‘ / åœ¨çº¿çŠ¶æ€
# - ç®¡ç†æ“ä½œï¼šPrometheus reloadã€æ¸…ç©º TSDBã€Grafana åˆ·æ–°
# - è°ƒåº¦ä»»åŠ¡ï¼šè‡ªåŠ¨åŒæ­¥ Prometheus èŠ‚ç‚¹ã€æœˆåº¦åŸºçº¿ã€æ¯æ—¥æ±‡æ€»
# - "æ¨¡å¼äºŒï¼šé¢æ¿ç®¡æ§"â€”â€”èŠ‚ç‚¹æ¯åˆ†é’Ÿä» /config/<instance> æ‹‰é…ç½®

import os
import sqlite3
import subprocess
from contextlib import contextmanager
import requests
from flask import Flask, jsonify, request, Response
from flask_cors import CORS
from apscheduler.schedulers.background import BackgroundScheduler
from dotenv import load_dotenv
from datetime import datetime, timedelta
import logging

# ========== ç¯å¢ƒå˜é‡ ==========
load_dotenv("settings.env")
PROM_URL = os.getenv("PROM_URL", "http://127.0.0.1:19090")
PG_URL = os.getenv("PG_URL", "http://127.0.0.1:19091")
GRAFANA_URL = os.getenv("GRAFANA_URL", "http://127.0.0.1:3000")
GRAFANA_API_TOKEN = os.getenv("GRAFANA_API_TOKEN", "")

# ã€æ–°å¢ã€‘åŒæ­¥æ—¶ä½¿ç”¨çš„ job åç§°ï¼ˆé»˜è®¤ trafficcopï¼‰
PROM_JOB_NAME = os.getenv("PROM_JOB_NAME", "trafficcop")

TG_BOT_TOKEN = os.getenv("TG_BOT_TOKEN", "")
TG_CHAT_ID = os.getenv("TG_CHAT_ID", "")

DAILY_SUMMARY_HOUR = int(os.getenv("DAILY_SUMMARY_HOUR", "0"))
DAILY_SUMMARY_MINUTE = int(os.getenv("DAILY_SUMMARY_MINUTE", "20"))
DAILY_BASELINE_HOUR = int(os.getenv("DAILY_BASELINE_HOUR", "0"))
DAILY_BASELINE_MINUTE = int(os.getenv("DAILY_BASELINE_MINUTE", "10"))

PANEL_HOST = os.getenv("PANEL_HOST", "0.0.0.0")
PANEL_PORT = int(os.getenv("PANEL_PORT", "8000"))

DB_PATH = "/app/data/trafficcop.db"   # âœ… ä¿®æ”¹ï¼šå®¹å™¨å®é™…ä½¿ç”¨çš„æ•°æ®åº“è·¯å¾„

# ========== Flask ==========
app = Flask(__name__)
CORS(app)

# ========== é…ç½®æ—¥å¿— ==========
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ========== DB ==========
@contextmanager
def db_conn():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.commit()
        conn.close()

def init_db():
    with db_conn() as db:
        db.execute("""
        CREATE TABLE IF NOT EXISTS nodes (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            sort_order INTEGER DEFAULT 0,
            instance TEXT UNIQUE NOT NULL,
            display_name TEXT DEFAULT '',
            reset_day INTEGER DEFAULT 1,
            limit_bytes INTEGER DEFAULT 0,
            limit_mode TEXT DEFAULT 'double',
            bandwidth_bps INTEGER DEFAULT 0,
            created_at TEXT DEFAULT (datetime('now'))
        );
        """)
        db.execute("CREATE INDEX IF NOT EXISTS idx_nodes_sort ON nodes(sort_order DESC, id DESC);")

        db.execute("""
        CREATE TABLE IF NOT EXISTS baselines (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            instance TEXT NOT NULL,
            iface TEXT NOT NULL,
            month_key TEXT NOT NULL,
            rx_base INTEGER NOT NULL,
            tx_base INTEGER NOT NULL,
            created_at TEXT DEFAULT (datetime('now')),
            UNIQUE(instance, iface, month_key)
        );
        """)

# ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
init_db()

# ========== å·¥å…· ==========
def now_ts():
    return datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S UTC")

def get_current_date_tag():
    """è·å–å½“å‰æ—¥æœŸæ ‡ç­¾ï¼Œæ ¼å¼ï¼šYYYYMMDD"""
    return datetime.now().strftime("%Y%m%d")

def get_date_tag_from_timestamp(timestamp):
    """ä»æ—¶é—´æˆ³è·å–æ—¥æœŸæ ‡ç­¾"""
    if isinstance(timestamp, (int, float)):
        return datetime.fromtimestamp(timestamp).strftime("%Y%m%d")
    return datetime.now().strftime("%Y%m%d")

def prom_instant_query(expr: str):
    url = f"{PROM_URL}/api/v1/query"
    r = requests.get(url, params={"query": expr}, timeout=10)
    r.raise_for_status()
    data = r.json()
    if data.get("status") != "success":
        raise RuntimeError(f"Prom query failed: {data}")
    return data["data"]["result"]

def prom_range_query(expr: str, start: str, end: str, step: str = "1h"):
    """èŒƒå›´æŸ¥è¯¢ï¼Œæ”¯æŒå¸¦æ—¥æœŸæ ‡ç­¾çš„æŒ‡æ ‡"""
    url = f"{PROM_URL}/api/v1/query_range"
    params = {
        "query": expr,
        "start": start,
        "end": end,
        "step": step
    }
    r = requests.get(url, params=params, timeout=30)
    r.raise_for_status()
    data = r.json()
    if data.get("status") != "success":
        raise RuntimeError(f"Prom range query failed: {data}")
    return data["data"]["result"]

def pg_delete_instance(job: str, instance: str):
    try:
        url = f"{PG_URL}/metrics/job/{job}/instance/{instance}"
        requests.delete(url, timeout=8)
    except Exception:
        pass

def tg_send(text: str):
    """
    Telegram æ¶ˆæ¯æ¨é€
    ç»Ÿä¸€ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼šTG_BOT_TOKEN + TG_CHAT_ID
    """
    token = os.getenv("TG_BOT_TOKEN")
    chat_id = os.getenv("TG_CHAT_ID")

    if not token or not chat_id:
        logger.warning("TG_BOT_TOKEN æˆ– TG_CHAT_ID æœªé…ç½®ï¼Œè·³è¿‡æ¨é€")
        return

    url = f"https://api.telegram.org/bot{token}/sendMessage"
    params = {
        "chat_id": chat_id,
        "text": text
    }

    try:
        resp = requests.get(url, params=params, timeout=10)
        if resp.status_code == 200:
            logger.info("âœ… TG æ¨é€æˆåŠŸ")
        else:
            logger.error(f"âŒ TG æ¨é€å¤±è´¥: {resp.status_code}, {resp.text}")
    except Exception as e:
        logger.exception("TG æ¨é€å¼‚å¸¸", exc_info=e)

def hostport_from_url(url: str) -> str:
    """
    æå– URL ä¸­çš„ host:port éƒ¨åˆ†
    ä¾‹å¦‚: http://127.0.0.1:19091 -> 127.0.0.1:19091
    """
    try:
        from urllib.parse import urlparse
        u = urlparse(url)
        return f"{u.hostname}:{u.port}" if u.port else u.hostname
    except Exception:
        return url

# ========== ä¿®å¤ï¼šç»Ÿä¸€ä½¿ç”¨ node_id è·å–æµé‡æ•°æ® ==========
def get_traffic_by_node_id(node_id):
    """
    æ ¹æ® node_id è·å–æµé‡æ•°æ®
    """
    try:
        # æŸ¥è¯¢ RX æµé‡
        rx_query = f'traffic_rx_bytes_total{{job="{PROM_JOB_NAME}", node_id="{node_id}"}}'
        rx_results = prom_instant_query(rx_query)
        
        # æŸ¥è¯¢ TX æµé‡  
        tx_query = f'traffic_tx_bytes_total{{job="{PROM_JOB_NAME}", node_id="{node_id}"}}'
        tx_results = prom_instant_query(tx_query)
        
        rx_total = 0
        tx_total = 0
        
        # ç´¯åŠ æ‰€æœ‰æ¥å£çš„ RX æµé‡
        for s in rx_results:
            if "value" in s:
                rx_total += float(s["value"][1])
        
        # ç´¯åŠ æ‰€æœ‰æ¥å£çš„ TX æµé‡
        for s in tx_results:
            if "value" in s:
                tx_total += float(s["value"][1])
                
        return rx_total, tx_total
        
    except Exception as e:
        logger.warning(f"è·å–èŠ‚ç‚¹ {node_id} æµé‡å¤±è´¥: {e}")
        return 0, 0

# ========== èŠ‚ç‚¹å‘ç°ï¼ˆå¢å¼ºç‰ˆï¼‰ ==========
def discover_instances():
    """
    ä¼˜å…ˆï¼š/api/v1/label/instance/values?match[]=up{job="<PROM_JOB_NAME>"}
    å…¶æ¬¡ï¼š/api/v1/targets -> data.activeTargets[*].labels.instance ï¼ˆjob åŒ¹é…ï¼‰
    å…œåº•ï¼š/api/v1/query?query=up -> metric.instance
    """
    inst = set()

    # 1) label valuesï¼ˆå¸¦ match è¿‡æ»¤åˆ°æŒ‡å®š jobï¼‰
    try:
        url = f"{PROM_URL}/api/v1/label/instance/values"
        r = requests.get(url, params={"match[]": f'up{{job="{PROM_JOB_NAME}"}}'}, timeout=8)
        r.raise_for_status()
        data = r.json()
        if data.get("status") == "success":
            for v in data.get("data", []):
                if v:
                    inst.add(v)
    except Exception as e:
        logger.warning(f"discover via label values failed: {e}")

    # 2) targets
    if not inst:
        try:
            r = requests.get(f"{PROM_URL}/api/v1/targets", timeout=8)
            r.raise_for_status()
            data = r.json()
            targets = data.get("data", {}).get("activeTargets", []) or []
            for t in targets:
                labels = t.get("labels", {})
                if labels.get("job") == PROM_JOB_NAME:
                    iv = labels.get("instance")
                    if iv:
                        inst.add(iv)
        except Exception as e:
            logger.warning(f"discover via targets failed: {e}")

    # 3) up æŸ¥è¯¢å…œåº•ï¼ˆä¸é™åˆ¶ jobï¼Œä½†èƒ½æŠŠ instance æ‰¾å‡ºæ¥ï¼‰
    if not inst:
        try:
            res = prom_instant_query("up")
            for s in res:
                iv = s.get("metric", {}).get("instance")
                if iv:
                    inst.add(iv)
        except Exception as e:
            logger.warning(f"discover via query up failed: {e}")

    return sorted(inst)

# ========== ä¿®å¤ï¼šèŠ‚ç‚¹è‡ªåŠ¨åŒæ­¥ ==========
def sync_nodes_from_prometheus():
    """
    ä» Prometheus æŠ“å–èŠ‚ç‚¹ä¿¡æ¯å¹¶åŒæ­¥åˆ°æ•°æ®åº“
    åŸºäº node_id è¿›è¡ŒåŒæ­¥ï¼Œinstance åç§°å¯ä»¥éšæ—¶ç¼–è¾‘
    """
    try:
        # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„ Prometheus series æŸ¥è¯¢æ ¼å¼
        series = prom_series([
            f'push_time_seconds{{job="{PROM_JOB_NAME}"}}',
            f'traffic_rx_bytes_total{{job="{PROM_JOB_NAME}"}}',
            f'traffic_tx_bytes_total{{job="{PROM_JOB_NAME}"}}'
        ])
    except Exception as e:
        logger.warning(f"sync_nodes_from_prometheus/series failed: {e}")
        return

    pg_hp = hostport_from_url(PG_URL)
    prom_self = "localhost:9090"

    for s in series:
        labels = dict(s)
        inst = labels.get("instance")
        nid = labels.get("node_id")

        # è·³è¿‡ pushgateway / prometheus è‡ªèº«
        if inst in (pg_hp, prom_self):
            continue

        # å¿…é¡»æœ‰ node_id æ‰å¤„ç†
        if not nid or not nid.isdigit():
            continue
            
        nid = int(nid)
        
        with db_conn() as db:
            cur = db.execute("SELECT id, instance FROM nodes WHERE id=?", (nid,))
            existing = cur.fetchone()
            
            if not existing:
                # æ–°èŠ‚ç‚¹æ³¨å†Œ
                db.execute("""
                    INSERT INTO nodes(id, instance, display_name, sort_order, reset_day, limit_bytes, limit_mode, bandwidth_bps)
                    VALUES(?,?,?,?,?,?,?,?)
                """, (nid, inst, inst, 0, 1, 0, "double", 0))
                logger.info(f"æ–°èŠ‚ç‚¹æ³¨å†Œ: node_id={nid}, instance={inst}")
            else:
                # å·²å­˜åœ¨èŠ‚ç‚¹ï¼Œæ›´æ–° instanceï¼ˆå¦‚æœä¸åŒï¼‰
                existing_inst = existing["instance"]
                if existing_inst != inst:
                    db.execute("UPDATE nodes SET instance=? WHERE id=?", (inst, nid))
                    logger.info(f"æ›´æ–°å®ä¾‹åç§°: node_id={nid}, ä» {existing_inst} æ”¹ä¸º {inst}")

# === ä¿®å¤ï¼šPrometheus /api/v1/series å¤šåŒ¹é…æŸ¥è¯¢ ===
def prom_series(matchers):
    """
    matchers: list[str], ä¾‹å¦‚ [
        'push_time_seconds{job="trafficcop"}',
        'traffic_rx_bytes_total{job="trafficcop"}',
    ]
    è¿”å›ï¼šlist[dict]ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª label-setï¼ˆç›´æ¥å¯ dict(s)ï¼‰
    """
    try:
        params = []
        for m in matchers:
            params.append(("match[]", m))
        resp = requests.get(f"{PROM_URL}/api/v1/series", params=params, timeout=5)
        resp.raise_for_status()
        js = resp.json()
        if js.get("status") != "success":
            raise RuntimeError(f"bad status: {js}")
        return js.get("data", [])
    except Exception as e:
        logger.warning(f"prom_series failed: {e}")
        return []

# ========== èŠ‚ç‚¹ CRUD ==========
@app.post("/nodes/register")
def register_node():
    """
    èŠ‚ç‚¹åˆæ¬¡å®‰è£…æ—¶è°ƒç”¨ï¼š
    - è‹¥å·²æœ‰ node_idï¼ˆä¾‹å¦‚é‡è£…åä¿ç•™ï¼‰ï¼Œä¼ å…¥åˆ™ç›´æ¥è¿”å›è¯¥èŠ‚ç‚¹ä¿¡æ¯ï¼›
    - è‹¥æ²¡æœ‰ï¼Œé¢æ¿åˆ›å»ºä¸€æ¡è®°å½•å¹¶åˆ†é…è‡ªå¢ IDï¼ˆSQLite AUTOINCREMENT ä¿è¯ä¸å¤ç”¨ï¼‰ã€‚
    è¯·æ±‚JSONï¼š
      { "instance": "node-01", "display_name": "node-01" }
    å“åº”JSONï¼š
      { "ok": true, "node_id": 12, "push_path": "/metrics/job/trafficcop/node_id/12/instance/node-01" }
    """
    data = request.get_json(force=True) if request.data else {}
    instance = (data.get("instance") or "").strip() or None
    display_name = (data.get("display_name") or instance or "").strip()

    with db_conn() as db:
        # å»ºä¸€æ¡ç©ºä½å³å¯ï¼ˆä¸è¦æ±‚ instance å¿…å¡«ï¼Œåç»­å¯æ”¹åï¼‰
        cur = db.execute("""
            INSERT INTO nodes(instance, display_name, sort_order, reset_day, limit_bytes, limit_mode, bandwidth_bps)
            VALUES(?,?,?,?,?,?,?)
        """, (instance or f"pending-{datetime.utcnow().timestamp():.0f}", display_name or "", 0, 1, 0, "double", 0))
        node_id = cur.lastrowid

        # å–å›å®Œæ•´è®°å½•
        cur = db.execute("SELECT * FROM nodes WHERE id=?", (node_id,))
        row = dict(cur.fetchone())

    # å‘Šè¯‰å®‰è£…è„šæœ¬ï¼šPushgateway åˆ†ç»„è·¯å¾„è¦å¸¦ node_idï¼ˆç»ˆèº«IDï¼‰+ instance
    # ä¾‹ï¼šhttp://<PG_URL>/metrics/job/trafficcop/node_id/12/instance/node-01
    push_path = f"/metrics/job/trafficcop/node_id/{node_id}/instance/{instance or f'node-{node_id}'}"
    return jsonify({"ok": True, "node_id": node_id, "push_path": push_path, "row": row})

@app.post("/admin/force-update/<int:node_id>")
def force_update_node(node_id: int):
    """å¼ºåˆ¶æ›´æ–°æŒ‡å®šèŠ‚ç‚¹çš„æµé‡æ•°æ® - ä½¿ç”¨ node_id"""
    try:
        # å…ˆåˆ é™¤è¯¥èŠ‚ç‚¹çš„ Pushgateway æ•°æ®
        url = f"{PG_URL}/metrics/job/{PROM_JOB_NAME}/node_id/{node_id}"
        requests.delete(url, timeout=8)

        # ç«‹å³å†™å…¥ 0 å€¼ï¼Œä¿è¯é¢æ¿ç«‹åˆ»å½’é›¶
        metrics = f"""
traffic_rx_bytes_total{{job="{PROM_JOB_NAME}", node_id="{node_id}"}} 0
traffic_tx_bytes_total{{job="{PROM_JOB_NAME}", node_id="{node_id}"}} 0
"""
        requests.post(url, data=metrics.encode("utf-8"), timeout=8)

        log_msg = f"å·²å¼ºåˆ¶æ›´æ–°å¹¶æ¸…é›¶èŠ‚ç‚¹ {node_id} çš„æµé‡æ•°æ®"
        logger.info(log_msg)
        return jsonify({"ok": True, "msg": log_msg})
    except Exception as e:
        return jsonify({"ok": False, "msg": str(e)}), 500

@app.get("/admin/force-update-web/<int:node_id>")
def force_update_node_web(node_id: int):
    """Web ç‰ˆæœ¬çš„å¼ºåˆ¶æ›´æ–°ï¼ˆæ¸…é›¶åç«‹å³å½’é›¶æ˜¾ç¤ºï¼‰"""
    try:
        with db_conn() as db:
            cur = db.execute("SELECT instance FROM nodes WHERE id=?", (node_id,))
            row = cur.fetchone()
            if not row:
                return Response("<h3>èŠ‚ç‚¹ä¸å­˜åœ¨</h3>", mimetype="text/html", status=404)
            instance = row["instance"]

        # åˆ é™¤ Pushgateway æ•°æ®
        url = f"{PG_URL}/metrics/job/{PROM_JOB_NAME}/node_id/{node_id}"
        requests.delete(url, timeout=8)

        # å†™å…¥ 0 å€¼
        metrics = f"""
traffic_rx_bytes_total{{job="{PROM_JOB_NAME}", node_id="{node_id}"}} 0
traffic_tx_bytes_total{{job="{PROM_JOB_NAME}", node_id="{node_id}"}} 0
"""
        requests.post(url, data=metrics.encode("utf-8"), timeout=8)

        html = f"""<html><body style="font-family:system-ui; padding:24px;">
        <h3>âœ… å·²å¼ºåˆ¶æ›´æ–°å¹¶æ¸…é›¶èŠ‚ç‚¹ {node_id}({instance})</h3>
        <p>èŠ‚ç‚¹çš„æµé‡æ•°æ®å·²è¢«æ¸…é›¶ï¼Œå¹¶ç«‹å³åœ¨é¢æ¿å½’é›¶ã€‚</p>
        <p><a href="/nodes" target="_blank">è¿”å›èŠ‚ç‚¹åˆ—è¡¨</a></p>
        </body></html>"""
        return Response(html, mimetype="text/html")
    except Exception as e:
        return Response(f"<pre>æ›´æ–°å¤±è´¥: {e}</pre>", mimetype="text/html", status=500)

def get_traffic_with_date_tags(node_id=None, instance=None, date_tag=None):
    """
    æŸ¥è¯¢å¸¦æ—¥æœŸæ ‡ç­¾çš„æµé‡æ•°æ® - ä¼˜å…ˆä½¿ç”¨ node_id
    """
    if not date_tag:
        date_tag = get_current_date_tag()
    
    # ä¼˜å…ˆä½¿ç”¨ node_id
    if node_id:
        base_query = f'{{job="{PROM_JOB_NAME}", date="{date_tag}", node_id="{node_id}"}}'
    elif instance:
        base_query = f'{{job="{PROM_JOB_NAME}", date="{date_tag}", instance="{instance}"}}'
    else:
        return {}
    
    queries = {
        'rx': f'traffic_rx_bytes_total{base_query}',
        'tx': f'traffic_tx_bytes_total{base_query}',
        'push_time': f'push_time_seconds{base_query}'
    }
    
    results = {}
    for metric, query in queries.items():
        try:
            data = prom_instant_query(query)
            results[metric] = data
        except Exception as e:
            logger.warning(f"Query failed for {metric}: {e}")
            results[metric] = []
    
    return results

def get_traffic_history(node_id, days=7):
    """
    è·å–èŠ‚ç‚¹å†å²æµé‡æ•°æ® - ä½¿ç”¨ node_id
    """
    end_time = datetime.now()
    start_time = end_time - timedelta(days=days)
    
    start_str = start_time.isoformat() + 'Z'
    end_str = end_time.isoformat() + 'Z'
    
    # ä½¿ç”¨ node_id æŸ¥è¯¢
    rx_query = f'traffic_rx_bytes_total{{job="{PROM_JOB_NAME}", node_id="{node_id}"}}'
    tx_query = f'traffic_tx_bytes_total{{job="{PROM_JOB_NAME}", node_id="{node_id}"}}'
    
    try:
        rx_data = prom_range_query(rx_query, start_str, end_str, "1h")
        tx_data = prom_range_query(tx_query, start_str, end_str, "1h")
        
        return {
            'rx': rx_data,
            'tx': tx_data,
            'period': {
                'start': start_str,
                'end': end_str,
                'days': days
            }
        }
    except Exception as e:
        logger.error(f"Failed to get traffic history for node {node_id}: {e}")
        return None

#  === å·¥å…·å‡½æ•°ï¼Œäººç±»å¯è¯»å­—èŠ‚ ===
def human_bytes(n: int) -> str:
    if not n:
        return "0 B"
    units = ["B","KB","MB","GB","TB","PB"]
    v = float(n)
    i = 0
    while v >= 1024 and i < len(units)-1:
        v /= 1024.0
        i += 1
    s = f"{v:.2f}".rstrip("0").rstrip(".")
    return f"{s} {units[i]}"

def gb_str_from_bytes(b: int) -> str:
    gb = (b or 0) / (1024**3)
    return f"{gb:.2f}".rstrip("0").rstrip(".")

@app.get("/nodes")
def list_nodes():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    cur.execute("SELECT * FROM nodes ORDER BY sort_order ASC, id ASC")
    rows = cur.fetchall()
    conn.close()

    out = []
    for x in rows:
        node_id = str(x["id"])
        inst = x["instance"]
        online = True

        rx, tx = get_traffic_by_node_id(node_id)
        row_dict = dict(x)  # âœ… è½¬æ¢æˆ dictï¼Œæ–¹ä¾¿ç”¨ .get()

        limit_mode = row_dict.get("limit_mode", "double")
        if limit_mode == "upload":
            used_val = tx
        elif limit_mode == "download":
            used_val = rx
        else:
            used_val = rx + tx

        limit_bytes = row_dict.get("limit_bytes", 0)
        usage_ratio = None
        if limit_bytes and limit_bytes > 0:
            usage_ratio = round(used_val / limit_bytes * 100, 2)

        mode_map = {"double": "åŒå‘", "download": "ä¸‹è¡Œ", "upload": "ä¸Šè¡Œ"}
        limit_mode_cn = mode_map.get(limit_mode, limit_mode)

        row = {
            "æ’åºID":        x["sort_order"],
            "èŠ‚ç‚¹ID":        x["id"],
            "æ˜¾ç¤ºåç§°":      x["display_name"],
            "å®ä¾‹":          x["instance"],
            "é™é¢(GB)":      gb_str_from_bytes(limit_bytes),
            "bandwidth_bps": row_dict.get("bandwidth_bps", 0),
            "é™æµæ¨¡å¼":      limit_mode_cn,
            "åœ¨çº¿çŠ¶æ€":      online,
            "é‡ç½®æ—¥":        row_dict.get("reset_day", 1),
            "used_bytes":    used_val,   # âœ… æ–°å¢æ•°å€¼å­—æ®µ
            "å·²ç”¨æµé‡":      human_bytes(used_val),
            "ä½¿ç”¨æ¯”ä¾‹(%)":   usage_ratio if usage_ratio is not None else "ä¸é™",
            "ç¼–è¾‘":          f"http://45.78.23.232:8000/edit-node?id={x['id']}"
        }
        out.append(row)

    return jsonify(out)


@app.get("/admin/debug-date-metrics")
def admin_debug_date_metrics():
    """è°ƒè¯•æ—¥æœŸæ ‡ç­¾æŒ‡æ ‡"""
    current_date = get_current_date_tag()
    out = {
        "current_date_tag": current_date,
        "prom_job": PROM_JOB_NAME
    }
    
    # æµ‹è¯•å„ç§æ—¥æœŸæ ‡ç­¾æŸ¥è¯¢
    test_queries = [
        f'push_time_seconds{{job="{PROM_JOB_NAME}", date="{current_date}"}}',
        f'traffic_rx_bytes_total{{job="{PROM_JOB_NAME}", date="{current_date}"}}',
        f'traffic_tx_bytes_total{{job="{PROM_JOB_NAME}", date="{current_date}"}}',
        f'push_time_seconds{{job="{PROM_JOB_NAME}"}}',  # æ— æ—¥æœŸæ ‡ç­¾å¯¹æ¯”
    ]
    
    for query in test_queries:
        try:
            result = prom_instant_query(query)
            out[query] = {
                "count": len(result),
                "samples": result[:3]  # å‰3ä¸ªæ ·æœ¬
            }
        except Exception as e:
            out[query] = {"error": str(e)}
    
    return jsonify(out)

# === å·¥å…·å‡½æ•°ï¼šäººç±»å¯è¯»å­—èŠ‚ã€GB å­—ç¬¦ä¸² ===
def _human_bytes(n: float) -> str:
    try:
        v = float(n or 0)
    except Exception:
        v = 0.0
    units = ["B", "KB", "MB", "GB", "TB", "PB"]
    i = 0
    while v >= 1024 and i < len(units) - 1:
        v /= 1024.0
        i += 1
    s = f"{v:.2f}".rstrip("0").rstrip(".")
    return f"{s} {units[i]}"

def _gb_str_from_bytes(b: int) -> str:
    try:
        gb = (b or 0) / (1024 ** 3)
    except Exception:
        gb = 0.0
    # ä¿ç•™ä¸¤ä½å°æ•°ï¼Œä½†å»æ‰å°¾éš 0
    return f"{gb:.2f}".rstrip("0").rstrip(".")

# === æ–°å¢ï¼šä»…ç”¨äº Grafana è¡¨æ ¼çš„ç²¾ç®€è§†å›¾ï¼Œä¸å½±å“ /nodes ===
@app.get("/nodes_table")
def list_nodes_table():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()
    cur.execute("SELECT * FROM nodes ORDER BY sort_order ASC, id ASC")
    rows = cur.fetchall()
    conn.close()

    rx_map, tx_map = {}, {}
    # å¯ä»¥æ ¹æ® Prometheus æˆ–æ•°æ®åº“æ•°æ®æ›´æ–° rx_map/tx_map

    out = []
    mode_map = {"double": "åŒå‘", "download": "ä¸‹è¡Œ", "upload": "ä¸Šè¡Œ"}
    for x in rows:
        node_id = str(x["id"])
        inst = x["instance"]
        online = True
        row_dict = dict(x)  # âœ… è½¬æ¢æˆ dict

        rx = rx_map.get("id:" + node_id) or rx_map.get("inst:" + inst, 0)
        tx = tx_map.get("id:" + node_id) or tx_map.get("inst:" + inst, 0)

        limit_mode = row_dict.get("limit_mode", "double")
        if limit_mode == "upload":
            used_val = tx
        elif limit_mode == "download":
            used_val = rx
        else:
            used_val = (rx or 0) + (tx or 0)

        limit_bytes = row_dict.get("limit_bytes", 0)
        usage_ratio = None
        if limit_bytes and limit_bytes > 0:
            usage_ratio = round(used_val / limit_bytes * 100, 2)

        row = {
            "æ’åºID":      x["sort_order"],
            "èŠ‚ç‚¹ID":      x["id"],
            "æ˜¾ç¤ºåç§°":    x["display_name"],
            "å®ä¾‹":        x["instance"],
            "é™é¢(GB)":    _gb_str_from_bytes(limit_bytes),
            "é™æµæ¨¡å¼":    mode_map.get(limit_mode, limit_mode),
            "åœ¨çº¿çŠ¶æ€":    online,
            "é‡ç½®æ—¥":      row_dict.get("reset_day", 1),
            "used_bytes":  used_val,   # âœ… æ–°å¢æ•°å€¼å­—æ®µ
            "å·²ç”¨æµé‡":    _human_bytes(used_val),
            "ä½¿ç”¨æ¯”ä¾‹(%)": usage_ratio if usage_ratio is not None else "ä¸é™",
            "ç¼–è¾‘":        f"http://45.78.23.232:8000/edit-node?id={x['id']}",
        }
        out.append(row)

    return jsonify(out)


@app.post("/nodes")
def create_node():
    data = request.get_json(force=True)
    instance = data.get("instance", "").strip()
    if not instance or not all(c.isalnum() or c in "._-" for c in instance):
        return jsonify({"error":"invalid instance"}), 400

    display_name = data.get("display_name", instance)  # âš¡ å¦‚æœæ²¡ä¼ ï¼Œç”¨ instance ä½œä¸ºé»˜è®¤æ˜¾ç¤ºå
    sort_order = int(data.get("sort_order", 0))
    reset_day = int(data.get("reset_day", 1))
    limit_bytes = int(data.get("limit_bytes", 0))
    limit_mode = data.get("limit_mode", "double")
    bandwidth_bps = int(data.get("bandwidth_bps", 0))

    with db_conn() as db:
        db.execute("""
            INSERT INTO nodes(instance, display_name, sort_order, reset_day, limit_bytes, limit_mode, bandwidth_bps)
            VALUES(?,?,?,?,?,?,?)
        """, (instance, display_name, sort_order, reset_day, limit_bytes, limit_mode, bandwidth_bps))

        cur = db.execute("SELECT * FROM nodes WHERE instance=?", (instance,))
        node = dict(cur.fetchone())

    return jsonify(node), 201

@app.patch("/nodes/<int:node_id>")
def update_node(node_id: int):
    data = request.get_json(force=True)
    cols = ["sort_order", "display_name", "reset_day", "limit_bytes", "limit_mode", "bandwidth_bps", "instance"]
    sets, vals = [], []
    for c in cols:
        if c in data:
            sets.append(f"{c}=?")
            vals.append(data[c])
    if not sets:
        return jsonify({"error":"empty update"}), 400

    vals.append(node_id)
    with db_conn() as db:
        db.execute(f"UPDATE nodes SET {', '.join(sets)} WHERE id=?", vals)
        cur = db.execute("SELECT * FROM nodes WHERE id=?", (node_id,))
        row = cur.fetchone()
        if not row:
            return jsonify({"error":"not found"}), 404
        node = dict(row)

    return jsonify(node)

# â€”â€” èŠ‚ç‚¹ç¼–è¾‘ï¼ˆè¡¨å•ï¼‰ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# åŒæ—¶æ”¯æŒä¸¤ç§è·¯ç”±ï¼š
# 1) /edit-node?id=<id>    ï¼ˆé…åˆ Grafana æŒ‰é’®çš„ query å½¢å¼ï¼‰
# 2) /edit-node/<id>       ï¼ˆç›´æ¥è·¯å¾„å½¢å¼ï¼‰
def _coerce_int(v, default=0, min_value=None, max_value=None):
    try:
        x = int(v)
    except Exception:
        x = default
    if min_value is not None:
        x = max(min_value, x)
    if max_value is not None:
        x = min(max_value, x)
    return x

def _limit_mode_options(current):
    # (å€¼, ä¸­æ–‡å, æ˜¯å¦é€‰ä¸­)
    opts = [
        ("double",  "åŒå‘",   current == "double"),
        ("download","ä»…ä¸‹è¡Œ", current == "download"),
        ("upload",  "ä»…ä¸Šè¡Œ", current == "upload"),
    ]
    return "\n".join(
        f'<option value="{v}" {"selected" if sel else ""}>{cn}</option>'
        for v, cn, sel in opts
    )

@app.get("/edit-node")
@app.get("/edit-node/<int:path_node_id>")
def edit_node_form(path_node_id=None):
    from html import escape
    node_id = path_node_id or _coerce_int(request.args.get("id"), 0)
    if not node_id:
        return Response("<h3>ç¼ºå°‘ node_id</h3>", mimetype="text/html", status=400)

    with db_conn() as db:
        cur = db.execute("SELECT * FROM nodes WHERE id=?", (node_id,))
        row = cur.fetchone()
        if not row:
            return Response("<h3>èŠ‚ç‚¹ä¸å­˜åœ¨</h3>", mimetype="text/html", status=404)
        n = dict(row)

    # å±•ç¤ºæ—¶ç”¨ GiBï¼Œä¿ç•™æ•´æ•°è¾“å…¥æ›´ç›´è§‚ï¼›å°æ•°å¯æ”¯æŒåˆ° 2 ä½
    limit_gb = 0 if int(n["limit_bytes"]) == 0 else (float(n["limit_bytes"]) / (1024**3))
    limit_gb_str = f"{limit_gb:.2f}".rstrip("0").rstrip(".")  # å»æ‰æ— ç”¨å°æ•°

    html = f"""<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>ç¼–è¾‘èŠ‚ç‚¹ {node_id}</title>
  <style>
    body {{ font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; padding: 24px; }}
    form {{ max-width: 560px; }}
    label {{ display:block; margin: 10px 0 4px; color:#333; }}
    input, select {{ width: 100%; padding: 8px 10px; box-sizing: border-box; }}
    .row {{ display:flex; gap:12px; }}
    .row .col {{ flex:1; }}
    .actions {{ margin-top:16px; display:flex; gap:8px; }}
    button {{ padding: 8px 12px; cursor: pointer; }}
    .hint {{ color:#888; font-size:12px; }}
  </style>
</head>
<body>
  <h2>ç¼–è¾‘èŠ‚ç‚¹ ID {node_id}</h2>
  <form method="post" action="/edit-node?id={node_id}">
    <label>æ’åºID</label>
    <input type="number" name="sort_order" value="{n['sort_order']}" />

    <label>æ˜¾ç¤ºåç§°</label>
    <input type="text" name="display_name" value="{escape(n['display_name'] or '')}" />

    <label>èŠ‚ç‚¹åç§°</label>
    <input type="text" name="display_name" value="{escape(n['instance'] or '')}" />

    <div class="row">
      <div class="col">
        <label>é™é¢ (GB)</label>
        <input type="text" name="limit_gb" value="{limit_gb_str}" />
        <div class="hint">0 è¡¨ç¤ºä¸é™åˆ¶ï¼›æ”¯æŒå°æ•°ï¼Œå¦‚ 10.5</div>
      </div>
      <div class="col">
        <label>é™æµæ¨¡å¼</label>
 <select name="limit_mode">
  {_limit_mode_options(n['limit_mode'])}
</select>
      </div>
    </div>

    <div class="row">
      <div class="col">
        <label>é‡ç½®æ—¥</label>
        <input type="number" name="reset_day" min="1" max="31" value="{n['reset_day']}" />
        <div class="hint">æ¯æœˆ 1â€“31 æ—¥è‡ªåŠ¨é‡ç½®</div>
      </div>
      <div class="col">
        <label>å¸¦å®½ (Mbps)</label>
       <input type="number" name="bandwidth_mbps" value="{int(n['bandwidth_bps'] / 1000000) if n['bandwidth_bps'] else 0}" />
      <div class="hint">ç¤ºä¾‹ï¼š100 = 100 Mbpsï¼Œ1000 = 1 Gbps</div>
      </div>
    </div>

    <div class="actions">
      <button type="submit">ä¿å­˜ä¿®æ”¹</button>
      <a href="/nodes" target="_blank"><button type="button">æŸ¥çœ‹ /nodes</button></a>
    </div>
  </form>
</body>
</html>"""
    return Response(html, mimetype="text/html")

@app.post("/edit-node")
@app.post("/edit-node/<int:path_node_id>")
def edit_node_submit(path_node_id=None):
    node_id = path_node_id or _coerce_int(request.args.get("id"), 0)
    if not node_id:
        return jsonify({"error": "missing node_id"}), 400

    # å–è¡¨å•å¹¶åšåŸºæœ¬æ ¡éªŒ/è½¬æ¢
    sort_order    = _coerce_int(request.form.get("sort_order", 0), 0)
    display_name  = (request.form.get("display_name") or "").strip()

    # é™é¢ï¼šæ”¯æŒå°æ•° GB
    try:
        limit_gb = float((request.form.get("limit_gb") or "0").strip())
        limit_bytes = 0 if limit_gb <= 0 else int(limit_gb * (1024**3))
    except Exception:
        limit_bytes = 0

    limit_mode    = (request.form.get("limit_mode") or "double").strip()
    if limit_mode not in ("double", "download", "upload"):
        limit_mode = "double"

    reset_day     = _coerce_int(request.form.get("reset_day", 1), 1, 1, 28)
    bandwidth_mbps = _coerce_int(request.form.get("bandwidth_mbps", 0), 0)
    bandwidth_bps = bandwidth_mbps * 1000000  # Mbps è½¬ bps

    with db_conn() as db:
        db.execute(
            """
            UPDATE nodes
               SET sort_order=?, display_name=?, limit_bytes=?, limit_mode=?, reset_day=?, bandwidth_bps=?
             WHERE id=?
            """,
            (sort_order, display_name, limit_bytes, limit_mode, reset_day, bandwidth_bps, node_id),
        )

    # ç®€å•æˆåŠŸé¡µ
    html = f"""<!doctype html>
<html><body style="font-family: system-ui; padding:24px;">
  <h3>èŠ‚ç‚¹ {node_id} å·²æ›´æ–° âœ…</h3>
  <p><a href="/nodes" target="_blank">æŸ¥çœ‹ /nodes JSON</a></p>
  <p><a href="javascript:window.close()">å…³é—­çª—å£</a></p>
</body></html>"""
    return Response(html, mimetype="text/html")
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

@app.delete("/nodes/<int:node_id>")
def delete_node(node_id: int):
    with db_conn() as db:
        cur = db.execute("SELECT instance FROM nodes WHERE id=?", (node_id,))
        row = cur.fetchone()
        if not row:
            return jsonify({"error":"not found"}), 404
        instance = row["instance"]
        db.execute("DELETE FROM nodes WHERE id=?", (node_id,))
    pg_delete_instance("trafficcop", instance)  # ä¿æŒä½ ç°æœ‰è°ƒç”¨
    return jsonify({"ok": True})

@app.get("/config/id/<int:node_id>")
def get_config_by_id(node_id: int):
    with db_conn() as db:
        cur = db.execute("SELECT * FROM nodes WHERE id=?", (node_id,))
        row = cur.fetchone()
        if not row:
            return jsonify({"error": "node_id not found"}), 404
        node = dict(row)

    cfg = {
        "node_id": node["id"],
        "instance": node["instance"],
        "display_name": node["display_name"],
        "reset_day": node["reset_day"],
        "limit_bytes": node["limit_bytes"],
        "limit_mode": node["limit_mode"],
        "bandwidth_bps": node["bandwidth_bps"],
        "updated_at": now_ts(),
    }
    return jsonify(cfg)


@app.get("/config/<instance>")
def get_config(instance: str):
    with db_conn() as db:
        cur = db.execute("SELECT * FROM nodes WHERE instance=?", (instance,))
        row = cur.fetchone()
        if not row:
            return jsonify({"error":"instance not registered"}), 404
        node = dict(row)
    cfg = {
        "instance": node["instance"],
        "display_name": node["display_name"],
        "reset_day": node["reset_day"],
        "limit_bytes": node["limit_bytes"],
        "limit_mode": node["limit_mode"],
        "bandwidth_bps": node["bandwidth_bps"],
        "updated_at": now_ts()
    }
    return jsonify(cfg)

# ========== ç®¡ç†æ“ä½œ ==========
@app.post("/admin/reload-prom")
def reload_prom():
    try:
        out = subprocess.run(
            ["docker", "exec", "trafficcop-prometheus", "kill", "-HUP", "1"],
            capture_output=True, text=True, check=False
        )
        return jsonify({"ok": True, "stdout": out.stdout, "stderr": out.stderr})
    except Exception as e:
        return jsonify({"ok": False, "msg": str(e)}), 500

@app.post("/admin/clear-tsdb")
def clear_tsdb():
    try:
        subprocess.run(["docker", "stop", "trafficcop-prometheus"], check=True)
        subprocess.run("rm -rf /www/trafficcop-panel/prometheus_data/*", shell=True, check=False)
        subprocess.run(["docker", "start", "trafficcop-prometheus"], check=True)
        return jsonify({"ok": True, "msg": "TSDB cleared and prometheus restarted"})
    except Exception as e:
        return jsonify({"ok": False, "msg": str(e)}), 500

@app.post("/admin/refresh-grafana")
def refresh_grafana():
    if not GRAFANA_API_TOKEN:
        return jsonify({"ok": True, "msg": "no grafana token; nothing to do"})
    try:
        headers = {"Authorization": f"Bearer {GRAFANA_API_TOKEN}"}
        r = requests.get(f"{GRAFANA_URL}/api/datasources", headers=headers, timeout=10)
        _ = r.json()
        return jsonify({"ok": True, "msg": "grafana ping ok"})
    except Exception as e:
        return jsonify({"ok": False, "msg": str(e)}), 500

# âš¡ ç«‹å³è§¦å‘èŠ‚ç‚¹åŒæ­¥ï¼ˆä¿ç•™ä½ çš„è·¯ç”±åï¼Œä½†å†…éƒ¨ç”¨å¢å¼ºå‘ç°ï¼‰
@app.post("/admin/sync-nodes")
def admin_sync_nodes():
    try:
        before = []
        with db_conn() as db:
            cur = db.execute("SELECT instance FROM nodes")
            before = [r["instance"] for r in cur.fetchall()]
        sync_nodes_from_prometheus()
        after = []
        with db_conn() as db:
            cur = db.execute("SELECT instance FROM nodes")
            after = [r["instance"] for r in cur.fetchall()]
        added = sorted(set(after) - set(before))
        return jsonify({"ok": True, "added": added, "total": len(after)})
    except Exception as e:
        return jsonify({"ok": False, "msg": str(e)}), 500

# ã€æ–°å¢ã€‘GET ç‰ˆï¼Œé€‚åˆåœ¨ Grafana æ–‡æœ¬é¢æ¿é‡Œæ”¾ä¸€ä¸ªâ€œåŒæ­¥èŠ‚ç‚¹â€é“¾æ¥
@app.get("/admin/sync-nodes-web")
def admin_sync_nodes_web():
    try:
        sync_nodes_from_prometheus()
        html = """<html><body style="font-family:system-ui">
        <h3>åŒæ­¥å·²è§¦å‘</h3>
        <p>å·²å°è¯•ä» Prometheus åŒæ­¥èŠ‚ç‚¹ã€‚è¿”å› Grafana åˆ·æ–°è¡¨æ ¼å³å¯ã€‚</p>
        <p><a href="/nodes" target="_blank">æŸ¥çœ‹å½“å‰ /nodes</a></p>
        </body></html>"""
        return Response(html, mimetype="text/html")
    except Exception as e:
        return Response(f"<pre>sync failed: {e}</pre>", mimetype="text/html", status=500)

# ã€æ–°å¢ã€‘SQL è°ƒè¯•æ¥å£ï¼šçœ‹å‘ç°ç»“æœ + DB ç°çŠ¶
@app.get("/admin/debug-nodes")
def admin_debug_nodes():
    out = {"job": PROM_JOB_NAME}

    # label values
    try:
        r = requests.get(
            f"{PROM_URL}/api/v1/label/instance/values",
            params={"match[]": f'up{{job="{PROM_JOB_NAME}"}}'},
            timeout=8,
        )
        r.raise_for_status()
        data = r.json()
        out["label_values"] = data.get("data", []) if data.get("status") == "success" else []
    except Exception as e:
        out["label_values_error"] = str(e)

    # targets
    try:
        r = requests.get(f"{PROM_URL}/api/v1/targets", timeout=8)
        r.raise_for_status()
        data = r.json()
        targets = data.get("data", {}).get("activeTargets", []) or []
        out["targets_instances"] = sorted(
            {t.get("labels", {}).get("instance")
             for t in targets if t.get("labels", {}).get("job") == PROM_JOB_NAME and t.get("labels", {}).get("instance")}
        )
    except Exception as e:
        out["targets_error"] = str(e)

    # up å…œåº•
    try:
        res = prom_instant_query("up")
        out["query_up_instances"] = sorted({s.get("metric", {}).get("instance") for s in res if s.get("metric", {}).get("instance")})
    except Exception as e:
        out["query_up_error"] = str(e)

    # series æ£€æŸ¥ node_id æ˜¯å¦å‡ºç°
    try:
        series = prom_series([f'push_time_seconds{{job="{PROM_JOB_NAME}"}}'])
        out["series_samples"] = series[:10]  # å–å‰ 10 ä¸ªï¼Œé¿å…å¤ªé•¿
    except Exception as e:
        out["series_error"] = str(e)

    # DB
    with db_conn() as db:
        cur = db.execute("SELECT * FROM nodes ORDER BY sort_order DESC, id DESC")
        rows = [dict(r) for r in cur.fetchall()]
        out["db_count"] = len(rows)
        out["db_instances"] = [r["instance"] for r in rows]
        out["db_ids"] = [r["id"] for r in rows]

    return jsonify(out)


# ========== è°ƒåº¦å™¨ ==========
from datetime import datetime
import sqlite3
import logging

logger = logging.getLogger(__name__)

DB_PATH = os.getenv("DB_PATH", "./data/trafficcop.db")

def baseline_monthly_for_due_nodes():
    """
    æ¯æœˆåŸºçº¿é‡ç½®ä»»åŠ¡ - ä½¿ç”¨ baselines è¡¨è®°å½•é‡ç½®ç‚¹
    è€Œä¸æ˜¯ç›´æ¥æ›´æ–° nodes.used_bytes
    """
    try:
        today = datetime.now().day
        logger.info(f"[baseline] å¼€å§‹æ£€æŸ¥åˆ°æœŸèŠ‚ç‚¹ (today={today})")

        with db_conn() as db:
            # æ‰¾å‡º reset_day = ä»Šå¤©çš„èŠ‚ç‚¹
            cur = db.execute("SELECT id, instance, reset_day FROM nodes WHERE reset_day = ?", (today,))
            due_nodes = cur.fetchall()

            if not due_nodes:
                logger.info("[baseline] æ²¡æœ‰åˆ°æœŸèŠ‚ç‚¹")
                return

            current_date = get_current_date_tag()

            for node_id, instance, reset_day in due_nodes:
                logger.info(f"[baseline] èŠ‚ç‚¹ {instance} (id={node_id}) åˆ°æœŸï¼Œå‡†å¤‡å†™å…¥åŸºçº¿")

                # è·å– Prometheus å½“å‰æµé‡ä½œä¸ºåŸºçº¿
                rx_query = f'traffic_rx_bytes_total{{job="{PROM_JOB_NAME}", instance="{instance}"}}'
                tx_query = f'traffic_tx_bytes_total{{job="{PROM_JOB_NAME}", instance="{instance}"}}'

                try:
                    rx_data = prom_instant_query(rx_query)
                    tx_data = prom_instant_query(tx_query)

                    rx_val = float(rx_data[0]["value"][1]) if rx_data else 0
                    tx_val = float(tx_data[0]["value"][1]) if tx_data else 0

                    db.execute("""
                        INSERT OR REPLACE INTO baselines(instance, iface, month_key, rx_base, tx_base)
                        VALUES(?,?,?,?,?)
                    """, (instance, "total", datetime.now().strftime("%Y%m"), int(rx_val), int(tx_val)))

                    tg_send(f"ğŸ“Š èŠ‚ç‚¹ {instance} (ID={node_id}) å·²é‡ç½®æœˆåº¦åŸºçº¿ RX={rx_val} TX={tx_val}")

                except Exception as e2:
                    logger.error(f"[baseline] è·å– {instance} æµé‡å¤±è´¥: {e2}")

    except Exception as e:
        logger.exception("[baseline] æ‰§è¡Œå¼‚å¸¸", exc_info=e)


def daily_summary_to_tg():
    """
    æ¯æ—¥æ±‡æ€»ä»»åŠ¡ - ä» Prometheus è·å–æµé‡å¹¶æ¨é€åˆ° TG
    """
    try:
        current_date = get_current_date_tag()

        # ä¼˜å…ˆä½¿ç”¨å¸¦æ—¥æœŸæ ‡ç­¾çš„æŒ‡æ ‡
        rx_results = prom_instant_query(
            f'traffic_rx_bytes_total{{job="{PROM_JOB_NAME}", date="{current_date}"}}'
        )
        tx_results = prom_instant_query(
            f'traffic_tx_bytes_total{{job="{PROM_JOB_NAME}", date="{current_date}"}}'
        )

        usage_map = {}
        detail_map = {}

        # ç´¯åŠ  RX
        for s in rx_results:
            inst = s["metric"].get("instance")
            if not inst or "value" not in s:
                continue
            val = float(s["value"][1])
            usage_map[inst] = usage_map.get(inst, 0) + val
            if inst not in detail_map:
                detail_map[inst] = [0, 0]
            detail_map[inst][0] = val  # RX

        # ç´¯åŠ  TX
        for s in tx_results:
            inst = s["metric"].get("instance")
            if not inst or "value" not in s:
                continue
            val = float(s["value"][1])
            usage_map[inst] = usage_map.get(inst, 0) + val
            if inst not in detail_map:
                detail_map[inst] = [0, 0]
            detail_map[inst][1] = val  # TX

        if not usage_map:
            tg_send("ğŸ“Š ä»Šæ—¥æ±‡æ€»ï¼šæ²¡æœ‰è·å–åˆ°èŠ‚ç‚¹æµé‡æ•°æ®")
            return

        # âœ… åŒæ­¥ä¿å­˜åˆ° history è¡¨
        save_daily_history(detail_map)

        # æ’åºå¹¶æ ¼å¼åŒ–å‰ 10 ä¸ªèŠ‚ç‚¹
        summary_lines = ["ğŸ“Š ä»Šæ—¥æµé‡æ±‡æ€»"]
        for inst, total in sorted(usage_map.items(), key=lambda x: x[1], reverse=True)[:10]:
            rx_val = detail_map.get(inst, [0, 0])[0]
            tx_val = detail_map.get(inst, [0, 0])[1]
            used_gb = round(total / (1024**3), 2)
            summary_lines.append(
                f"â€¢ {inst}: {used_gb} GB (Rx {round(rx_val/1024**3, 2)} / Tx {round(tx_val/1024**3, 2)})"
            )

        if len(usage_map) > 10:
            summary_lines.append(f"... å…¶ä½™ {len(usage_map) - 10} ä¸ªèŠ‚ç‚¹çœç•¥")

        tg_send("\n".join(summary_lines))

    except Exception as e:
        logger.exception("[summary] æ‰§è¡Œå¼‚å¸¸", exc_info=e)


scheduler = BackgroundScheduler(timezone="Asia/Shanghai")
scheduler.add_job(baseline_monthly_for_due_nodes, "cron",
                  hour=DAILY_BASELINE_HOUR, minute=DAILY_BASELINE_MINUTE, id="monthly_baseline")
scheduler.add_job(daily_summary_to_tg, "cron",
                  hour=DAILY_SUMMARY_HOUR, minute=DAILY_SUMMARY_MINUTE, id="daily_summary")
# âš¡ æ¯ 5 åˆ†é’Ÿè‡ªåŠ¨åŒæ­¥
scheduler.add_job(sync_nodes_from_prometheus, "interval", minutes=5, id="sync_nodes")

scheduler.start()


def save_daily_history(usage_map, date_str=None):
    """
    ä¿å­˜æ¯æ—¥æµé‡ç»Ÿè®¡åˆ° history è¡¨
    usage_map: { instance: (rx_bytes, tx_bytes) }
    date_str: æŒ‡å®šæ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰
    """
    if not date_str:
        date_str = datetime.now().strftime("%Y-%m-%d")

    try:
        with db_conn() as db:
            for inst, (rx, tx) in usage_map.items():
                node = db.execute("SELECT id FROM nodes WHERE instance=?", (inst,)).fetchone()
                if node:
                    db.execute("""
                        INSERT INTO history (node_id, date, rx_bytes, tx_bytes, total_bytes)
                        VALUES (?,?,?,?,?)
                    """, (node[0], date_str, int(rx), int(tx), int(rx+tx)))
        logger.info(f"[history] {date_str} å·²ä¿å­˜ {len(usage_map)} ä¸ªèŠ‚ç‚¹çš„æµé‡æ•°æ®")
    except Exception as e:
        logger.exception("[history] ä¿å­˜å¼‚å¸¸", exc_info=e)


@app.get("/healthz")
def healthz():
    return jsonify({"ok": True, "ts": now_ts()})

if __name__ == "__main__":
    print(f"[{now_ts()}] TrafficCop Panel API starting at {PANEL_HOST}:{PANEL_PORT}")
    app.run(host=PANEL_HOST, port=PANEL_PORT)
